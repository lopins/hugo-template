<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:site_name" content="Huabing Blog"><meta property="og:type" content="article"><meta property="og:image" content="https://images.unsplash.com/photo-1489619243109-4e0ea59cfe10?ixlib=rb-4.0.3&amp;ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&amp;auto=format&amp;fit=crop&amp;w=2070&amp;q=80"><meta property="twitter:image" content="https://images.unsplash.com/photo-1489619243109-4e0ea59cfe10?ixlib=rb-4.0.3&amp;ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&amp;auto=format&amp;fit=crop&amp;w=2070&amp;q=80"><meta name=title content="深入理解 Istio Metrics"><meta property="og:title" content="深入理解 Istio Metrics"><meta property="twitter:title" content="深入理解 Istio Metrics"><meta name=description content="Istio 为 Service Mesh 中的微服务提供了非常丰富的统计指标（Metrics），这些指标可以让运维人员随时监控应用程序中服务的健康状况，在系统出现线上故障之前就发现潜在问题并进行处理。本文将介绍 Istio Metrics 的实现机制，以帮助读者深入了解其原理。。"><meta property="og:description" content="Istio 为 Service Mesh 中的微服务提供了非常丰富的统计指标（Metrics），这些指标可以让运维人员随时监控应用程序中服务的健康状况，在系统出现线上故障之前就发现潜在问题并进行处理。本文将介绍 Istio Metrics 的实现机制，以帮助读者深入了解其原理。。"><meta property="twitter:description" content="Istio 为 Service Mesh 中的微服务提供了非常丰富的统计指标（Metrics），这些指标可以让运维人员随时监控应用程序中服务的健康状况，在系统出现线上故障之前就发现潜在问题并进行处理。本文将介绍 Istio Metrics 的实现机制，以帮助读者深入了解其原理。。"><meta property="twitter:card" content="summary"><meta name=keyword content="赵化冰, zhaohuabing, Zhaohuabing, , 赵化冰的网络日志, 赵化冰的博客, Zhaohuabing Blog, 博客, 个人网站, 互联网, Web, 云原生, PaaS, Istio, Kubernetes, 微服务, Microservice"><link rel="shortcut icon" href=/hugo-template/img/favicon.ico><title>深入理解 Istio Metrics | 赵化冰的博客 | Zhaohuabing Blog</title>
<link rel=canonical href=/hugo-template/post/2023-02-14-istio-metrics-deep-dive/><link rel=stylesheet href=/hugo-template/css/bootstrap.min.css><link rel=stylesheet href=/hugo-template/css/hugo-theme-cleanwhite.min.css><link rel=stylesheet href=/hugo-template/css/zanshang.css><link rel=stylesheet href=/hugo-template/css/font-awesome.all.min.css><script src=/hugo-template/js/jquery.min.js></script><script src=/hugo-template/js/bootstrap.min.js></script><script src=/hugo-template/js/hux-blog.min.js></script><script src=/hugo-template/js/lazysizes.min.js></script></head><nav class="navbar navbar-default navbar-custom navbar-fixed-top"><div class=container-fluid><div class="navbar-header page-scroll"><button type=button class=navbar-toggle>
<span class=sr-only>Toggle navigation</span>
<span class=icon-bar></span>
<span class=icon-bar></span>
<span class=icon-bar></span>
</button>
<a class=navbar-brand href=/>Huabing Blog</a></div><div id=huxblog_navbar><div class=navbar-collapse><ul class="nav navbar-nav navbar-right"><li><a href=/>All Posts</a></li><li><a href=/hugo-template/categories/books/>books</a></li><li><a href=/hugo-template/categories/open-source/>open source</a></li><li><a href=/hugo-template/categories/presentations/>presentations</a></li><li><a href=/hugo-template/categories/tech/>tech</a></li><li><a href=/archive//>ARCHIVE</a></li><li><a href=/notes//>NOTES</a></li><li><a href=/about//>ABOUT</a></li><li><a href=/hugo-template/search><i class="fa fa-search"></i></a></li></ul></div></div></div></nav><script>var $body=document.body,$toggle=document.querySelector(".navbar-toggle"),$navbar=document.querySelector("#huxblog_navbar"),$collapse=document.querySelector(".navbar-collapse");$toggle.addEventListener("click",handleMagic);function handleMagic(){$navbar.className.indexOf("in")>0?($navbar.className=" ",setTimeout(function(){$navbar.className.indexOf("in")<0&&($collapse.style.height="0px")},400)):($collapse.style.height="auto",$navbar.className+=" in")}</script><style type=text/css>header.intro-header{background-image:url(https://images.unsplash.com/photo-1489619243109-4e0ea59cfe10?ixlib=rb-4.0.3&ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&auto=format&fit=crop&w=2070&q=80)}</style><header class=intro-header><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><div class=post-heading><div class=tags><a class=tag href=/tags/istio title=Istio>Istio
</a><a class=tag href=/tags/envoy title=Envoy>Envoy
</a><a class=tag href=/tags/service-mesh title="Service Mesh">Service Mesh
</a><a class=tag href=/tags/metrics title=Metrics>Metrics</a></div><h1>深入理解 Istio Metrics</h1><h2 class=subheading></h2><span class=meta>Posted by
赵化冰
on
Tuesday, February 14, 2023</span></div></div></div></div></header><article><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
post-container"><p>Istio 为 Service Mesh 中的微服务提供了非常丰富的统计指标（Metrics），这些指标可以让运维人员随时监控应用程序中服务的健康状况，在系统出现线上故障之前就发现潜在问题并进行处理。本文将介绍 Istio Metrics 的实现机制，以帮助读者深入了解其原理。</p><p>备注：本文中 Stats 和 Metrics 均指统计指标；Tag 和 Label 均指统计指标中数据所带的标签，这些是 Envoy 和 Istio 对同一概念的不同称呼。</p><h1 id=envoy-stats>Envoy Stats</h1><p>Istio Metrics 是基于 Envoy Stats 机制进行扩展而实现的。要理解 Istio Metrics 的实现机制，我们需要先了解 Envoy Stats。Envoy Stats (Statistics 的缩写，即统计数据) 是 Envoy 中的一个公共模块，为 Envoy 中的各种 filter（如 HCM，TCP Proxy 等）和 Cluter 输出详尽的统计数据。</p><h2 id=envoy-stats-类型>Envoy Stats 类型</h2><p>Envoy 提供了三种类型的 stats：</p><ul><li><p>Counter：Counter 是一个只增不减的计数器，可以用于记录某些事情的发生次数，例如请求的总次数。只要不重置该计数器，请求总数的数量只会向上增长，越来越大。</p><p>例如下面的 envoy_cluster_upstream_rq_total 指标记录了 echo-service 这个 cluster 的处理的 HTTP 请求总数。</p><pre tabindex=0><code># TYPE  counter
envoy_cluster_upstream_rq_total{envoy_cluster_name=&#34;echo-service&#34;} 2742
</code></pre></li><li><p>Gauges：Gauges 是一个数值可以变大或者变小的指标，用于反应系统的当前状态，例如当前的活动连接数。</p><p>例如下面的 envoy_cluster_upstream_cx_active 指标记录了 echo-service 这个 cluster 当前的活动链接数。当前活动链接数随着接入客户端和并发请求数量的变化而变化，可能增大，也可能变小。</p><pre tabindex=0><code># TYPE envoy_cluster_upstream_cx_active gauge
envoy_cluster_upstream_cx_active{envoy_cluster_name=&#34;echo-service&#34;} 24
</code></pre></li><li><p>Histogram：如果我们想了解一个指标在某一段时间内的取值的分布情况，例如系统启动以来请求处理的耗时分布情况，则需要 Histogram 类型的指标。</p><p>例如下面的 historgram 指标 envoy_cluster_upstream_rq_time 展示了 echo-service 这个 cluster 的 HTTP 请求处理时长的分布情况。从 20 个 bucket 数据行可以看到请求的处理时长分布在 0 - 500 毫秒这个区间中，并可以看到落入每个区间的请求数量。sum 数据行记录了所有这些请求的总时长。count 数据行则是请求的总数。我们可以通过这些数据进一步计算出请求的 P50， P90，P99 百分数以及请求的平均耗时等统计数据。</p><pre tabindex=0><code># TYPE envoy_cluster_upstream_rq_time histogram
envoy_cluster_upstream_rq_time_bucket{envoy_cluster_name=&#34;echo-service&#34;,le=&#34;0.5&#34;} 653
envoy_cluster_upstream_rq_time_bucket{envoy_cluster_name=&#34;echo-service&#34;,le=&#34;1&#34;} 653
envoy_cluster_upstream_rq_time_bucket{envoy_cluster_name=&#34;echo-service&#34;,le=&#34;5&#34;} 906
envoy_cluster_upstream_rq_time_bucket{envoy_cluster_name=&#34;echo-service&#34;,le=&#34;10&#34;} 910
envoy_cluster_upstream_rq_time_bucket{envoy_cluster_name=&#34;echo-service&#34;,le=&#34;25&#34;} 911
envoy_cluster_upstream_rq_time_bucket{envoy_cluster_name=&#34;echo-service&#34;,le=&#34;50&#34;} 914
envoy_cluster_upstream_rq_time_bucket{envoy_cluster_name=&#34;echo-service&#34;,le=&#34;100&#34;} 914
envoy_cluster_upstream_rq_time_bucket{envoy_cluster_name=&#34;echo-service&#34;,le=&#34;250&#34;} 915
envoy_cluster_upstream_rq_time_bucket{envoy_cluster_name=&#34;echo-service&#34;,le=&#34;500&#34;} 916
envoy_cluster_upstream_rq_time_bucket{envoy_cluster_name=&#34;echo-service&#34;,le=&#34;1000&#34;} 916
envoy_cluster_upstream_rq_time_bucket{envoy_cluster_name=&#34;echo-service&#34;,le=&#34;2500&#34;} 916
envoy_cluster_upstream_rq_time_bucket{envoy_cluster_name=&#34;echo-service&#34;,le=&#34;5000&#34;} 916
envoy_cluster_upstream_rq_time_bucket{envoy_cluster_name=&#34;echo-service&#34;,le=&#34;10000&#34;} 916
envoy_cluster_upstream_rq_time_bucket{envoy_cluster_name=&#34;echo-service&#34;,le=&#34;30000&#34;} 916
envoy_cluster_upstream_rq_time_bucket{envoy_cluster_name=&#34;echo-service&#34;,le=&#34;60000&#34;} 916
envoy_cluster_upstream_rq_time_bucket{envoy_cluster_name=&#34;echo-service&#34;,le=&#34;300000&#34;} 916
envoy_cluster_upstream_rq_time_bucket{envoy_cluster_name=&#34;echo-service&#34;,le=&#34;600000&#34;} 916
envoy_cluster_upstream_rq_time_bucket{envoy_cluster_name=&#34;echo-service&#34;,le=&#34;1800000&#34;} 916
envoy_cluster_upstream_rq_time_bucket{envoy_cluster_name=&#34;echo-service&#34;,le=&#34;3600000&#34;} 916
envoy_cluster_upstream_rq_time_bucket{envoy_cluster_name=&#34;echo-service&#34;,le=&#34;+Inf&#34;} 916
envoy_cluster_upstream_rq_time_sum{envoy_cluster_name=&#34;echo-service&#34;} 1000.8500000000001364242052659392
envoy_cluster_upstream_rq_time_count{envoy_cluster_name=&#34;echo-service&#34;} 916
</code></pre></li></ul><h2 id=envoy-stats-的呈现方式>Envoy Stats 的呈现方式</h2><p>通过 envoy 的 admin 端口可以查询 stats 数据。Envoy 支持按照原始格式或者 prometheus 格式展示指标数据。</p><ul><li><p>原始格式：以 &ldquo;.&rdquo; 将 stats 的名称和该 stats 的各个 tag 连在一起作为指标名称。</p><p>下面的这个 stats 是一个 counter，表示 echo-service 这个 cluster 的 http1 请求总数:</p><pre tabindex=0><code>http.echo-service.downstream_rq_http1_total: 41  
</code></pre></li><li><p>Prometheus 格式：Envoy 会将指标名中的 tag 按照规则提取出来，生成符合 Prometheus 格式要求的指标数据。该接口可以作为数据提供给 Prometheus 进行抓取。</p><p>将上面的 stats 转换为 Prometheus 格式:</p><pre tabindex=0><code>envoy_http_downstream_rq_http1_total{envoy_http_conn_manager_prefix=&#34;echo-service&#34;} 41 
</code></pre></li></ul><p>通过管理接口的两个不同的 URL http://localhost:$(admin_port)/stats 和 http://localhost:$(admin_port)/stats/prometheus 可以以原始格式和 Prometheus 格式查看 envoy 中的所有 stats 数据。</p><p><img src=https://zhaohuabing.com/static/img/2023-02-14-istio-metrics-deep-dive/stats.png alt>
<img src=https://zhaohuabing.com/static/img/2023-02-14-istio-metrics-deep-dive/stats-prometheus.png alt></p><h1 id=istio-metrics>Istio Metrics</h1><p>虽然 Envoy 通过 stats提供了非常完善的统计数据，但是 Envoy 提供的这些指标是基于 cluster 进行统计的，例如某个 cluster 的请求次数，请求耗时，成功率等。从单个代理的角度来看，这些指标已经足以用于分析代理和其 upstream server 的工作状况，但这些指标用在 service mesh 的场景中是不够的。</p><h2 id=istio-对-envoy-stats-的扩展>Istio 对 Envoy Stats 的扩展</h2><p>在 service mesh 中，我们需要查看 service 维度的统计指标，包括某个 service 的调用次数，请求耗时，成功率等。因此 Istio 对 Envoy 进行了扩展，增加了一些 service 维度的 stats（Istio 中也称 metrics）。Istio 还在 service 的指标中加入丰富的 tag（Istio 中也称为 label），包括请求端 service 的信息（cluster，namespace，workload，canonical service），服务端 service 的信息（cluster，namespace，service name，version 等），以让微服务运维和开发人员准确监控系统的运行情况并找到有问题的服务。</p><p>Istio 为 Envoy sidecar 增加了以下 stats：</p><p>七层（HTTP/gRPC）指标：</p><ul><li>istio_requests_total（counter）：统计 service 的 HTTP 请求数量。</li><li>istio_request_duration_milliseconds （Histogram）：统计 service 的 HTTP 请求时延。</li><li>istio_request_bytes：（Histogram）：统计 service 的 HTTP 请求大小。</li><li>istio_response_bytes：（Histogram）：统计 service 的 HTTP 响应大小。</li><li>istio_request_messages_total：（counter）：统计 service 的 gRPC 请求消息数量。</li><li>istio_response_messages_total：（counter）：统计 service 的 gRPC 响应消息数量。</li></ul><p>四层（TCP）指标：</p><ul><li>istio_tcp_sent_bytes_total（counter）：统计 service 发送的 TCP 字节数量。</li><li>istio_tcp_received_bytes_total（counter）：统计 service 接收的 TCP 字节数量。</li><li>istio_tcp_connections_opened_total（counter）：统计 service 打开的 TCP 链接数量。</li><li>istio_tcp_connections_closed_total（counter）：统计 service 关闭的 TCP 链接数量。</li></ul><p>Istio 提供的一个服务级别的指标的示例：</p><pre tabindex=0><code>istio_requests_total{
    response_code=&#34;200&#34;,
    reporter=&#34;source&#34;,
    source_workload=&#34;reviews-v3&#34;,
    source_workload_namespace=&#34;default&#34;,
    source_principal=&#34;spiffe://cluster.local/ns/default/sa/bookinfo-reviews&#34;,
    source_app=&#34;reviews&#34;,
    source_version=&#34;v3&#34;,
    source_cluster=&#34;Kubernetes&#34;,
    destination_workload=&#34;ratings-v1&#34;,
    destination_workload_namespace=&#34;default&#34;,
    destination_principal=&#34;spiffe://cluster.local/ns/default/sa/bookinfo-ratings&#34;,
    destination_app=&#34;ratings&#34;,destination_version=&#34;v1&#34;,
    destination_service=&#34;ratings.default.svc.cluster.local&#34;,
    destination_service_name=&#34;ratings&#34;,
    destination_service_namespace=&#34;default&#34;,
    destination_cluster=&#34;Kubernetes&#34;,
    request_protocol=&#34;http&#34;,
    response_flags=&#34;-&#34;,
    grpc_response_status=&#34;&#34;,
    connection_security_policy=&#34;unknown&#34;,
    source_canonical_service=&#34;reviews&#34;,
    destination_canonical_service=&#34;ratings&#34;,
    source_canonical_revision=&#34;v3&#34;,
    destination_canonical_revision=&#34;v1&#34;} 
    32
</code></pre><p>从上面的例子中可以看到，Istio 为每个指标提供了丰富的 tag（Istio 中又称为 label），其中比较重要的 tag 的含义见下表：</p><table><thead><tr><th>Tag</th><th>说明</th><th>示例</th><th>备注</th></tr></thead><tbody><tr><td>reporter</td><td>数据的上报端</td><td>source/destination</td><td>如果数据是从 client 端的 sidecar proxy 上报的，则取值为 source；如果是从 server 端的 sidecar proxy 上报的，则取值为 destination</td></tr><tr><td>source_cluster</td><td>Client 端所属的 Cluster</td><td></td><td></td></tr><tr><td>source_workload_namespace</td><td>Client 端所属的 namespace</td><td>default</td><td></td></tr><tr><td>source_workload</td><td>Client 端的 workload</td><td>reviews-v3</td><td>deployment 名称</td></tr><tr><td>source_app</td><td>Client 端的应用名称</td><td>reviews</td><td>pod 的 app label</td></tr><tr><td>source_version</td><td>Client 端的版本号</td><td>v3</td><td>pod 的 version label</td></tr><tr><td>source_canonical_service</td><td>Client 端的标准服务名</td><td>reviews</td><td>pod label <code>service.istio.io/canonical-name</code> 或者 <code>app.kubernetes.io/name</code> 或者 <code>app</code> 或者 deployment name（优先级由高到底）</td></tr><tr><td>source_canonical_revision</td><td>Client 端的标准版本号</td><td>v3</td><td>pod label <code>service.istio.io/canonical-revision</code> 或者 <code>app.kubernetes.io/version</code> 或者 <code>version</code> 或者 &ldquo;latest&rdquo;（优先级由高到底）</td></tr><tr><td>destination_cluster</td><td>Server 端所属的 Cluster</td><td></td><td></td></tr><tr><td>destination_workload_namespace</td><td>Server 端所属的 namespace</td><td>default</td><td></td></tr><tr><td>destination_workload</td><td>Server 端的 workload</td><td>ratings-v1</td><td>deployment 名称</td></tr><tr><td>destination_app</td><td>Server 端的应用名称</td><td>ratings</td><td>pod 的 app label</td></tr><tr><td>destination_service</td><td>请求的服务全限定名称</td><td>ratings.default.svc.cluster.local</td><td>如果采用 VS 进行路由，service 是 VS 路由指向的服务</td></tr><tr><td>destination_service_name</td><td>请求的服务名</td><td>ratings</td><td>如果采用 VS 进行路由，service 是 VS 路由指向的服务</td></tr><tr><td>destination_service_namespace</td><td>请求服务所在 namespace</td><td>default</td><td>如果采用 VS 进行路由，service 和实际的 workload 的 namespace 可能不同</td></tr><tr><td>destination_version</td><td>Server 端的版本号</td><td>v1</td><td>pod 的 version label</td></tr><tr><td>destination_canonical_service</td><td>Server 端的标准服务名</td><td>ratings</td><td>pod label <code>service.istio.io/canonical-name</code> 或者 <code>app.kubernetes.io/name</code> 或者 <code>app</code> 或者 deployment name（优先级由高到底）</td></tr><tr><td>destination_canonical_revision</td><td>Server 端的标准版本号</td><td>v1</td><td>pod label <code>service.istio.io/canonical-revision</code> 或者 <code>app.kubernetes.io/version</code> 或者 <code>version</code> 或者 &ldquo;latest&rdquo;（优先级由高到底）</td></tr></tbody></table><h2 id=istio-metadata-exchange-filter>Istio Metadata Exchange Filter</h2><p>从上文中 Istio metrics 的例子中可以看到，sidecar proxy 在上报 metrics 时会将对端服务的相关信息作为 label 加入到上报数据中，包括对端的 cluster，workload_namespace，app，version，canonical_service，canonical_revision。那么 sidecar proxy 如何才能获取对端服务的这些信息呢？这就要依赖 Istio 的 Metadata Exchang 机制。</p><p>Istio 为 Envoy 添加了一个 Metadata Exchange Filter。该 Filter 会在两个通信的 sidecar 之间交换对方节点的 metdata 信息，并将这些 metadata 信息用于生成 metrics 的 label。</p><p>Metadata Exchange Filter 在四层和七层采用了不同的机制来交换对方节点的信息。</p><h3 id=七层的-metadata-exchange-机制>七层的 Metadata Exchange 机制</h3><p>Istio 在 envoy proxy 中加入了一个 http filter <a href=https://github.com/istio/proxy/tree/1.4.10/extensions/metadata_exchange>metadata exchange</a>。在 client 端，该 HTTP filter 在 HTTP 请求中添加了两个 header：<code>x-envoy-peer-metadata-id</code> 和 <code>x-envoy-peer-metadata</code>。用这个两个 header 将 client 节点的信息告知 server 端。 同样的，在 server 端，该 HTTP filter 也在 response 中增加了这两个 header，以用于将 server 节点的信息告知 client 端。这样请求两端的 sidecar proxy 就拿到了对端的节点信息，这些节点信息将作为 label 添加到生成的 metrics 中。</p><p><img src=https://zhaohuabing.com/static/img/2023-02-14-istio-metrics-deep-dive/metadata-exchange-http.png alt>
下面我们以 boookinfo demo 中 reviews 服务访问 ratings 服务为例对 Metadata Exchange 的过程进行说明：</p><p>reviews 的 sidecar proxy 在请求中加入了下面的 header：</p><pre tabindex=0><code>x-envoy-peer-metadata: ChsKDkFQUF9DT05UQUlORVJTEgkaB3Jldmlld3MKGgoKQ0xVU1RFUl9JRBIMGgpLdWJlcm5ldGVzCh4KDElOU1RBTkNFX0lQUxIOGgwxNzIuMTYuMC4xMzMKGQoNSVNUSU9fVkVSU0lPThIIGgYxLjE0LjUK0wEKBkxBQkVMUxLIASrFAQoQCgNhcHASCRoHcmV2aWV3cwofChFwb2QtdGVtcGxhdGUtaGFzaBIKGgg1OGI2NDc5YgokChlzZWN1cml0eS5pc3Rpby5pby90bHNNb2RlEgcaBWlzdGlvCiwKH3NlcnZpY2UuaXN0aW8uaW8vY2Fub25pY2FsLW5hbWUSCRoHcmV2aWV3cworCiNzZXJ2aWNlLmlzdGlvLmlvL2Nhbm9uaWNhbC1yZXZpc2lvbhIEGgJ2MwoPCgd2ZXJzaW9uEgQaAnYzChoKB01FU0hfSUQSDxoNY2x1c3Rlci5sb2NhbAojCgROQU1FEhsaGXJldmlld3MtdjMtNThiNjQ3OWItNjJydjUKFgoJTkFNRVNQQUNFEgkaB2RlZmF1bHQKTgoFT1dORVISRRpDa3ViZXJuZXRlczovL2FwaXMvYXBwcy92MS9uYW1lc3BhY2VzL2RlZmF1bHQvZGVwbG95bWVudHMvcmV2aWV3cy12MwoXChFQTEFURk9STV9NRVRBREFUQRICKgAKHQoNV09SS0xPQURfTkFNRRIMGgpyZXZpZXdzLXYz

x-envoy-peer-metadata-id: sidecar~172.16.0.133~reviews-v3-58b6479b-62rv5.default~default.svc.cluster.local
</code></pre><p>ratings 的 sidecar proxy 在响应中加入了下面的 header：</p><pre tabindex=0><code>x-envoy-peer-metadata: ChsKDkFQUF9DT05UQUlORVJTEgkaB3JhdGluZ3MKGgoKQ0xVU1RFUl9JRBIMGgpLdWJlcm5ldGVzCh0KDElOU1RBTkNFX0lQUxINGgsxNzIuMTYuMC42OQoZCg1JU1RJT19WRVJTSU9OEggaBjEuMTQuNQrVAQoGTEFCRUxTEsoBKscBChAKA2FwcBIJGgdyYXRpbmdzCiEKEXBvZC10ZW1wbGF0ZS1oYXNoEgwaCjg1Y2M0NmI2ZDQKJAoZc2VjdXJpdHkuaXN0aW8uaW8vdGxzTW9kZRIHGgVpc3RpbwosCh9zZXJ2aWNlLmlzdGlvLmlvL2Nhbm9uaWNhbC1uYW1lEgkaB3JhdGluZ3MKKwojc2VydmljZS5pc3Rpby5pby9jYW5vbmljYWwtcmV2aXNpb24SBBoCdjEKDwoHdmVyc2lvbhIEGgJ2MQoaCgdNRVNIX0lEEg8aDWNsdXN0ZXIubG9jYWwKJQoETkFNRRIdGhtyYXRpbmdzLXYxLTg1Y2M0NmI2ZDQtbjdxZGcKFgoJTkFNRVNQQUNFEgkaB2RlZmF1bHQKTgoFT1dORVISRRpDa3ViZXJuZXRlczovL2FwaXMvYXBwcy92MS9uYW1lc3BhY2VzL2RlZmF1bHQvZGVwbG95bWVudHMvcmF0aW5ncy12MQoXChFQTEFURk9STV9NRVRBREFUQRICKgAKHQoNV09SS0xPQURfTkFNRRIMGgpyYXRpbmdzLXYx

x-envoy-peer-metadata-id: sidecar~172.16.0.69~ratings-v1-85cc46b6d4-n7qdg.default~default.svc.cluster.local
</code></pre><p>x-envoy-peer-metadata 是经过 base64 编码的本节点的相关信息，Request 中的 metadata 解码后的内容如下：</p><pre tabindex=0><code>APP_CONTAINERS reviews
CLUSTER_ID Kubernetes
INSTANCE_IPS 172.16.0.133
ISTIO_VERSION 1.14.5

LABELS
app reviews
pod-template-hash 58b6479b
security.istio.io/tlsMode istio
service.istio.io/canonical-name reviews
service.istio.io/canonical-revision v3
version v3
MESH_ID cluster.local
NAME reviews-v3-58b6479b-62rv5
NAMESPACE default
OWNER kubernetes://apis/apps/v1/namespaces/default/deployments/reviews-v3
WORKLOAD_NAME reviews-v3
</code></pre><p>Response 中的 metadata 解码后的内容如下：</p><pre tabindex=0><code>APP_CONTAINERS ratings
CLUSTER_ID Kubernetes
INSTANCE_IPS 172.16.0.69
ISTIO_VERSION 1.14.5

LABELS
app ratings
pod-template-hash 85cc46b6d4
security.istio.io/tlsMode istio
service.istio.io/canonical-name ratings
service.istio.io/canonical-revision v1
version v1
MESH_ID cluster.local
NAME ratings-v1-85cc46b6d4-n7qdg
NAMESPACE default
OWNER kubernetes://apis/apps/v1/namespaces/default/deployments/ratings-v1
PLATFORM_METADATA
WORKLOAD_NAME ratings-v1
</code></pre><p>metadata 中的信息来自于 Envoy sidecar bootstrap 配置中的 node 部分。我们可以通过下面的命令查看 reviews-v3-58b6479b-62rv5 这个 pod 的 node metadata。</p><pre tabindex=0><code>istioctl proxy-config bootstrap reviews-v3-58b6479b-62rv5
</code></pre><pre tabindex=0><code>{
  &#34;bootstrap&#34;: {
    &#34;node&#34;: {
      &#34;id&#34;: &#34;sidecar~172.16.0.133~reviews-v3-58b6479b-62rv5.default~default.svc.cluster.local&#34;,
      &#34;cluster&#34;: &#34;reviews.default&#34;,
      &#34;metadata&#34;: {
        &#34;ANNOTATIONS&#34;: {…},
        &#34;APP_CONTAINERS&#34;: &#34;reviews&#34;,
        &#34;CLUSTER_ID&#34;: &#34;Kubernetes&#34;,
        &#34;ENVOY_PROMETHEUS_PORT&#34;: 15090,
        &#34;ENVOY_STATUS_PORT&#34;: 15021,
        &#34;INSTANCE_IPS&#34;: &#34;172.16.0.133&#34;,
        &#34;INTERCEPTION_MODE&#34;: &#34;REDIRECT&#34;,
        &#34;ISTIO_PROXY_SHA&#34;: &#34;1bb64f113319d0984fae32222335a833e560edac&#34;,
        &#34;ISTIO_VERSION&#34;: &#34;1.14.5&#34;,
        &#34;LABELS&#34;: {
          &#34;app&#34;: &#34;reviews&#34;,
          &#34;pod-template-hash&#34;: &#34;58b6479b&#34;,
          &#34;security.istio.io/tlsMode&#34;: &#34;istio&#34;,
          &#34;service.istio.io/canonical-name&#34;: &#34;reviews&#34;,
          &#34;service.istio.io/canonical-revision&#34;: &#34;v3&#34;,
          &#34;version&#34;: &#34;v3&#34;
        },
        &#34;MESH_ID&#34;: &#34;cluster.local&#34;,
        &#34;NAME&#34;: &#34;reviews-v3-58b6479b-62rv5&#34;,
        &#34;NAMESPACE&#34;: &#34;default&#34;,
        &#34;OWNER&#34;: &#34;kubernetes://apis/apps/v1/namespaces/default/deployments/reviews-v3&#34;,
        &#34;PILOT_SAN&#34;: […],
        &#34;POD_PORTS&#34;: &#34;[{\&#34;containerPort\&#34;:9080,\&#34;protocol\&#34;:\&#34;TCP\&#34;}]&#34;,
        &#34;PROV_CERT&#34;: &#34;var/run/secrets/istio/root-cert.pem&#34;,
        &#34;PROXY_CONFIG&#34;: {…},
        &#34;SERVICE_ACCOUNT&#34;: &#34;bookinfo-reviews&#34;,
        &#34;WORKLOAD_NAME&#34;: &#34;reviews-v3&#34;
      }
    }  
}
</code></pre><p>bootstrap 中的 node metadata 则是由 istio-agent 根据当前 pod 所在的 cluster，Namespace，名称，label 等相关信息生成的。</p><h3 id=四层的-metadata-exchange-机制>四层的 Metadata Exchange 机制</h3><p>对于 四层 的 Metrics，Istio 在 envoy proxy 中加入了一个 tcp filter <a href=https://github.com/istio/proxy/tree/1.4.10/src/envoy/tcp/metadata_exchange>metadata exchange</a> ，通过在应用数据前加入一个自定义的 metadata exchange 协议来获取对端节点的信息。该协议的格式非常简单，header 是一个魔数 <code>0x3D230467</code> 和 body 长度，内容则是 node metadata 信息，和 HTTP header 中的数据类似。</p><table><thead><tr><th>Header</th><th>body</th></tr></thead><tbody><tr><td>0x3D230467 | body 长度</td><td>Metadata id | metadata</td></tr></tbody></table><p>在 Istio service mesh 中，我们并不能保证 tcp 链接的两端都支持 metadata exchange 协议。例如，对端的 sidecar proxy 可能由于版本较低还不支持 metadata exchange，对端也可能由于没有部署 sidecar proxy 而无法支持。</p><p>为了解决该问题，Istio 采用了 TLS 的 ALPN 字段来和对端进行协商，以判断对端是否支持 metadata exchange 协议。支持 metadata exchange 协议的 sidecar proxy 在发送 TLS hello 消息时会在 APLN 字段中添加一个 istio-peer-exchange 协议。如果对端也支持 istio-peer-exchange ALPN，则双方 proxy 就会采用 metadata exchange 协议交换节点信息，如果没有，则会跳过该步骤。由于协议协商依赖 TLS 的 APLN，如果未启用 TLS，则 Istio 也不会启用 metadata exchange。</p><p>四层的 Metadata Exchange 协议如下图所示：</p><p><img src=https://zhaohuabing.com/static/img/2023-02-14-istio-metrics-deep-dive/metadata-exchange-tcp.png alt></p><p>Sidecar Proxy 通过七层或者四层的 Metadata Exchange 机制拿到对端的节点信息后，会保存到 Envoy 的 <a href=https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/advanced/data_sharing_between_filters#dynamic-state>filter state</a> 中，以供生成 metrics 时使用。</p><h2 id=istio-stats-filter>Istio Stats Filter</h2><p>Istio 还在 Envoy Proxy 增加了 Istio Stats Filter（七层和四层各有一个 stats filter） 来生成 Service 相关的 Metrics。该 Filter 利用 envoy 提供的 stats api 创建了前文描述的 <a href=#istio-%E5%AF%B9-envoy-stats-%E7%9A%84%E6%89%A9%E5%B1%95>service metrics</a>，并将从 <a href=https://www.envoyproxy.io/docs/envoy/latest/intro/arch_overview/advanced/data_sharing_between_filters#dynamic-state>filter state</a> 中获取到的对端节点的 metadata，将对端节点的信息作为 label 加入到生成的 metrics 数据中。</p><h2 id=istio-metrics-引发的内存问题>Istio Metrics 引发的内存问题</h2><p>由于 Metrics 数据的数量较大，往往是 Envoy 内存占用的一个主要罪魁祸首，例如这个<a href=https://www.zhaohuabing.com/istio-guide/docs/common-problem/envoy-stats-memory/>典型的 metrics 引发的 Envoy 内存溢出故障</a>。 因此在对 Istio Metrics 进行自定义设置，特别是添加 label 时需要特别注意。不要随意加入取值范围较大或者取值不确定的 label。增加 label会导致 metrics 占用的内存数量成倍增长。 例如增加一个取值范围为 10 的 label，会导致生成的 metrics 数据变为之前的 10 倍。 例如，加入 request path 作为 label，而 path 中又有一些参数变量，往往会生成大量的 metrics，最终导致 envoy 内存溢出。</p><h1 id=参考文档>参考文档</h1><ul><li><a href=https://blog.envoyproxy.io/envoy-stats-b65c7f363342>Envoy stats</a></li><li><a href="https://docs.google.com/document/d/1bWQAsrBZguk5HCmBVDEgEMVGS91r9uh3SIr7D7ELZBk/edit#heading=h.qex63c29z2to">Proxy Metadata Exchange</a></li><li><a href="https://blog.christianposta.com/understanding-istio-telemetry-v2/#:~:text=A%20metric%20is%20a%20counter,DISTRIBUTION%20measuring%20latency%20of%20requests">Understanding Istio Telemetry v2</a></li></ul><div class="entry-shang text-center"><p>「真诚赞赏，手留余香」</p><button class="zs show-zs btn btn-bred">赞赏支持</button></div><div class=zs-modal-bg></div><div class=zs-modal-box><div class=zs-modal-head><button type=button class=close>×</button>
<span class=author><a href=https://lopins.github.io/hugo-template/><img src=/hugo-template/img/favicon.png>Huabing Blog</a></span><p class=tip><i></i><span>真诚赞赏，手留余香</span></p></div><div class=zs-modal-body><div class=zs-modal-btns><button class="btn btn-blink" data-num=2>2元</button>
<button class="btn btn-blink" data-num=5>5元</button>
<button class="btn btn-blink" data-num=10>10元</button>
<button class="btn btn-blink" data-num=50>50元</button>
<button class="btn btn-blink" data-num=100>100元</button>
<button class="btn btn-blink" data-num=1>任意金额</button></div><div class=zs-modal-pay><button class="btn btn-bred" id=pay-text>2元</button><p>使用<span id=pay-type>微信</span>扫描二维码完成支付</p><img src=/hugo-template/img/reward/wechat-2.png id=pay-image></div></div><div class=zs-modal-footer><label><input type=radio name=zs-type value=wechat class=zs-type checked><span><span class=zs-wechat><img src=/hugo-template/img/reward/wechat-btn.png></span></label>
<label><input type=radio name=zs-type value=alipay class=zs-type class=zs-alipay><img src=/hugo-template/img/reward/alipay-btn.png></span></label></div></div><script type=text/javascript src=/hugo-template/js/reward.js></script><hr><ul class=pager><li class=previous><a href=/hugo-template/post/2023-02-06-aeraki-metrics/ data-toggle=tooltip data-placement=top title="Aeraki Mesh 提供服务级别的 Metrics">&larr;
Previous Post</a></li><li class=next><a href=/hugo-template/post/2023-02-24-aeraki-mesh-community-meeting-en/ data-toggle=tooltip data-placement=top title="Aeraki Mesh 社区例会 - 2023-02-23">Next
Post &rarr;</a></li></ul><link href=https://xxx.xxx.com/dist/Artalk.css rel=stylesheet><script src=https://xxx.xxx.com/dist/Artalk.js></script><div id=Comments></div><script>Artalk.init({el:"#Comments",pageKey:"https://lopins.github.io/hugo-template/post/2023-02-14-istio-metrics-deep-dive/",pageTitle:"深入理解 Istio Metrics",server:"https://xxx.xxx.com",site:"xxx blog"})</script></div><div class="col-lg-2 col-lg-offset-0
visible-lg-block
sidebar-container
catalog-container"><div class=side-catalog><hr class="hidden-sm hidden-xs"><h5><a class=catalog-toggle href=#>CATALOG</a></h5><ul class=catalog-body></ul></div></div><div class="col-lg-8 col-lg-offset-2
col-md-10 col-md-offset-1
sidebar-container"><section><hr class="hidden-sm hidden-xs"><h5><a href=/tags/>FEATURED TAGS</a></h5><div class=tags><a href=/tags/aeraki title=aeraki>aeraki
</a><a href=/tags/aeraki-mesh title="aeraki mesh">aeraki mesh
</a><a href=/tags/ambient-mesh title="ambient mesh">ambient mesh
</a><a href=/tags/api-gateway title="api gateway">api gateway
</a><a href=/tags/bitcoin title=bitcoin>bitcoin
</a><a href=/tags/blockchain title=blockchain>blockchain
</a><a href=/tags/cka title=cka>cka
</a><a href=/tags/cncf title=cncf>cncf
</a><a href=/tags/cryptocurrency title=cryptocurrency>cryptocurrency
</a><a href=/tags/digital-signature title="digital signature">digital signature
</a><a href=/tags/docker title=docker>docker
</a><a href=/tags/dubbo title=dubbo>dubbo
</a><a href=/tags/envoy title=envoy>envoy
</a><a href=/tags/envoy-gateway title="envoy gateway">envoy gateway
</a><a href=/tags/ingress title=ingress>ingress
</a><a href=/tags/istio title=istio>istio
</a><a href=/tags/jaeger title=jaeger>jaeger
</a><a href=/tags/kafka title=kafka>kafka
</a><a href=/tags/knowledge-graph title="knowledge graph">knowledge graph
</a><a href=/tags/kubecon title=kubecon>kubecon
</a><a href=/tags/kubernetes title=kubernetes>kubernetes
</a><a href=/tags/linux title=linux>linux
</a><a href=/tags/loadbalancer title=loadbalancer>loadbalancer
</a><a href=/tags/metaprotocol title=metaprotocol>metaprotocol
</a><a href=/tags/microservice title=microservice>microservice
</a><a href=/tags/network title=network>network
</a><a href=/tags/network-service-mesh title="network service mesh">network service mesh
</a><a href=/tags/nfv title=nfv>nfv
</a><a href=/tags/nodeport title=nodeport>nodeport
</a><a href=/tags/onap title=onap>onap
</a><a href=/tags/opentracing title=opentracing>opentracing
</a><a href=/tags/pilot title=pilot>pilot
</a><a href=/tags/proxy-protocol title="proxy protocol">proxy protocol
</a><a href=/tags/redis title=redis>redis
</a><a href=/tags/sdn title=sdn>sdn
</a><a href=/tags/security title=security>security
</a><a href=/tags/service-mesh title="service mesh">service mesh
</a><a href=/tags/tencent title=tencent>tencent
</a><a href=/tags/x-forwarded-for title=x-forwarded-for>x-forwarded-for</a></div></section><section><hr><h5>FRIENDS</h5><ul class=list-inline><li><a target=_blank href=https://zhaozhihan.com>Linda的博客</a></li></ul></section></div></div></div></article><footer><div class=container><div class=row><div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1"><ul class="list-inline text-center"><li><a href=mailto:youremail@gmail.com><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-envelope fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=/hugo-template/your%20wechat%20qr%20code%20image><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-weixin fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=https://github.com/yourgithub><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-github fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=https://www.linkedin.com/in/yourlinkedinid><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-linkedin fa-stack-1x fa-inverse"></i></span></a></li><li><a target=_blank href=https://stackoverflow.com/users/yourstackoverflowid><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fab fa-stack-overflow fa-stack-1x fa-inverse"></i></span></a></li><li><a href rel=alternate type=application/rss+xml title="Huabing Blog"><span class="fa-stack fa-lg"><i class="fas fa-circle fa-stack-2x"></i>
<i class="fas fa-rss fa-stack-1x fa-inverse"></i></span></a></li></ul><p class="copyright text-muted">Copyright &copy; Huabing Blog 2024<br><a href=https://themes.gohugo.io/hugo-theme-cleanwhite>CleanWhite Hugo Theme</a> by <a href=https://zhaohuabing.com>Huabing</a> |
<iframe style=margin-left:2px;margin-bottom:-5px frameborder=0 scrolling=0 width=100px height=20px src="https://ghbtns.com/github-btn.html?user=zhaohuabing&repo=hugo-theme-cleanwhite&type=star&count=true"></iframe></p></div></div></div></footer><script>function loadAsync(e,t){var s=document,o="script",n=s.createElement(o),i=s.getElementsByTagName(o)[0];n.src=e,t&&n.addEventListener("load",function(e){t(null,e)},!1),i.parentNode.insertBefore(n,i)}</script><script>$("#tag_cloud").length!==0&&loadAsync("/js/jquery.tagcloud.js",function(){$.fn.tagcloud.defaults={color:{start:"#bbbbee",end:"#0085a1"}},$("#tag_cloud a").tagcloud()})</script><script>loadAsync("https://cdn.jsdelivr.net/npm/fastclick@1.0.6/lib/fastclick.min.js",function(){var e=document.querySelector("nav");e&&FastClick.attach(e)})</script><script type=text/javascript>function generateCatalog(e){_containerSelector="div.post-container";var t,n,s,o,i,a=$(_containerSelector),r=a.find("h1,h2,h3,h4,h5,h6");return $(e).html(""),r.each(function(){t=$(this).prop("tagName").toLowerCase(),o="#"+$(this).prop("id"),n=$(this).text(),i=$('<a href="'+o+'" rel="nofollow">'+n+"</a>"),s=$('<li class="'+t+'_nav"></li>').append(i),$(e).append(s)}),!0}generateCatalog(".catalog-body"),$(".catalog-toggle").click(function(e){e.preventDefault(),$(".side-catalog").toggleClass("fold")}),loadAsync("/hugo-template/js/jquery.nav.js",function(){$(".catalog-body").onePageNav({currentClass:"active",changeHash:!1,easing:"swing",filter:"",scrollSpeed:700,scrollOffset:0,scrollThreshold:.2,begin:null,end:null,scrollChange:null,padding:80})})</script></body></html>